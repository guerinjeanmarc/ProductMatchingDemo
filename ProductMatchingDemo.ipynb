{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Matching Using Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Neo4j [Graph Data Science Client](https://neo4j.com/docs/graph-data-science-client/current/installation/) and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from graphdatascience import GraphDataScience\n",
    "except:\n",
    "    %pip install graphdatascience\n",
    "    from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set connection credentials and OpenAI api key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionUrl = str(input(\"Neo4j Database Url (press enter to use \\\"neo4j://localhost:7687\\\"): \") or \"neo4j://localhost:7687\")\n",
    "username = str(input(\"Username (press enter for \\\"neo4j\\\"): \") or \"neo4j\")\n",
    "password = input(\"Password: \")\n",
    "database = str(input(\"Database name (press enter for \\\"neo4j\\\"): \") or \"neo4j\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt='OpenAI API key: ')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY') # Needed for the last part: Product Matching using OpenAI text embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the database connection and return the Graph Data Science library version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience(connectionUrl, auth=(username, password))\n",
    "gds.set_database(database)\n",
    "print(gds.version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data\n",
    "Data has been downloaded from [openfoodfacts.org](https://world.openfoodfacts.org/cgi/search.pl?action=display&search_terms=ice&tagtype_0=countries&tag_contains_0=contains&tag_0=uk&tagtype_1=languages&tag_contains_1=contains&tag_1=en&sort_by=unique_scans_n&page_size=20)\n",
    "\n",
    "search criteria: \n",
    "['bread','ice','peas'] with country contains 'uk' and languages contains \"en\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "bread_df = pd.read_csv('openfoodfacts_export_bread_UK_en.csv', sep='\\t')\n",
    "ice_df = pd.read_csv('openfoodfacts_export_ice_UK_en.csv', sep='\\t')\n",
    "peas_df = pd.read_csv('openfoodfacts_export_peas_UK_en.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([bread_df, ice_df,peas_df], ignore_index=True, axis=0)\n",
    "all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_col = ['code', 'product_name_en','generic_name_en','quantity','serving_size',\n",
    "           'packaging_tags','brands_tags','categories_tags','labels_tags','countries_tags','stores_tags', \n",
    "           'ingredients_text_en','allergens_tags','traces_tags','packaging_1_shape',\n",
    "           'link','off:food_groups','off:food_groups_tags','off:nova_groups_tags','off:nutriscore_grade','off:nutriscore_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_df[min_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.dropna(subset=['product_name_en'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"create constraint if not exists for (p:Product) require (p.code) is node key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load product\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df \n",
    "merge (p:Product{code: df['code'], name:df['product_name_en']})\n",
    "set p.genericName = df['generic_name_en'], \n",
    "    p.quantity = df['quantity'], \n",
    "    p.servingSize = df['serving_size']\n",
    "\"\"\",\n",
    "params = {'df':df.to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load brands\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(df['brands_tags'],\",\") as brands\n",
    "unwind brands as brand\n",
    "match (p:Product {code: df['code']})\n",
    "merge (b:Brand {name:brand})\n",
    "merge (p)-[:HAS_BRAND]->(b)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['brands_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packaging\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['packaging_tags'],\"en:\",\"\"),\",\") as packagings\n",
    "unwind packagings as packaging\n",
    "match (p:Product {code: df['code']})\n",
    "merge (pa:Packaging {name:packaging})\n",
    "merge (p)-[:HAS_PACKAGING]->(pa)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['packaging_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load categories\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['categories_tags'],\"en:\",\"\"),\",\") as categories\n",
    "unwind categories as category\n",
    "match (p:Product {code: df['code']})\n",
    "merge (ca:Category {name:category})\n",
    "merge (p)-[:HAS_CATEGORY]->(ca)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['categories_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load labels\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['labels_tags'],\"en:\",\"\"),\",\") as labels\n",
    "unwind labels as label\n",
    "match (p:Product {code: df['code']})\n",
    "merge (l:Label {name:label})\n",
    "merge (p)-[:HAS_LABEL]->(l)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['labels_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load countries\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['countries_tags'],\"en:\",\"\"),\",\") as countries\n",
    "unwind countries as country\n",
    "match (p:Product {code: df['code']})\n",
    "merge (c:Country {name:country})\n",
    "merge (p)-[:HAS_COUNTRY]->(c)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['countries_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stores\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(df['stores_tags'],\",\") as stores\n",
    "unwind stores as store\n",
    "match (p:Product {code: df['code']})\n",
    "merge (s:Store {name:store})\n",
    "merge (p)-[:HAS_STORE]->(s)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['stores_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load allergens\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['allergens_tags'],\"en:\",\"\"),\",\") as allergens\n",
    "unwind allergens as allergen\n",
    "match (p:Product {code: df['code']})\n",
    "merge (a:Allergen {name:allergen})\n",
    "merge (p)-[:HAS_ALLERGEN]->(a)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['allergens_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load foodGroup1\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['off:food_groups'],\"en:\",\"\"),\",\") as foodgroups\n",
    "unwind foodgroups as foodgroup\n",
    "match (p:Product {code: df['code']})\n",
    "merge (c:Category {name:foodgroup})\n",
    "merge (p)-[:HAS_GROUP1]->(c)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['off:food_groups']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load foodGroup2\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(replace(df['off:food_groups_tags'],\"en:\",\"\"),\",\") as foodgroups\n",
    "unwind foodgroups as foodgroup\n",
    "match (p:Product {code: df['code']})\n",
    "merge (c:Category {name:foodgroup})\n",
    "merge (p)-[:HAS_GROUP2]->(c)\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['off:food_groups_tags']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ingredients as free text\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "match (p:Product {code: df['code']})\n",
    "set p.ingredients = df.ingredients_text_en\n",
    "\"\"\",\n",
    "params = {'df':df.dropna(subset=['ingredients_text_en']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugly clean\n",
    "gds.run_cypher(\"\"\"MATCH (p:Product ) where toString(p.genericName)=\"NaN\" set p.genericName = NULL\"\"\")\n",
    "gds.run_cypher(\"\"\"MATCH (p:Product ) where toString(p.quantity)=\"NaN\" set p.genericName = NULL\"\"\")\n",
    "gds.run_cypher(\"\"\"MATCH (p:Product ) where toString(p.servingSize)=\"NaN\" set p.genericName = NULL\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gds.run_cypher(\"\"\"\n",
    "call apoc.meta.stats\n",
    "YIELD labels\n",
    "\"\"\")\n",
    "pd.DataFrame([d.labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most represented category\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product)-[:HAS_CATEGORY]->(c:Category)\n",
    "RETURN c.name as category, count(p) as productCount\n",
    "ORDER BY productCount DESC\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most represented group1 category\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product)-[:HAS_GROUP1]->(c:Category)\n",
    "RETURN c.name as category, count(p) as productCount\n",
    "ORDER BY productCount DESC\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store - product\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Brand)--(p:Product)--(s:Store)\n",
    "    RETURN b.name as brand, s.name as store, count(p) as productCount order by productCount desc\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of product per brand\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Brand)--(p:Product)\n",
    "    RETURN b.name, count(p) as productCount order by productCount desc\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many products has labels, per brand\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH path=(b:Brand)--(p:Product)--(l:Label)\n",
    "    RETURN b.name as brand, \n",
    "        count(l) as totalLabelCount,  \n",
    "        count(distinct l) as uniqueLabel, \n",
    "        count(distinct p) as uniqueProduct,\n",
    "        count(l) / count(distinct p) as ratio\n",
    "    order by ratio desc\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find Similar Products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. based on categories - Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (p:Product {code:1216486})--(c)\n",
    "    with p, collect (c.name) as context\n",
    "    return p.name, p.genericName, p.quantity, p.ingredients, context\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar product to \"Garden Peas\"\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {code:1216486})-[r:HAS_ALLERGEN|HAS_GROUP1|HAS_GROUP2|HAS_LABEL*2]-(sim:Product)\n",
    "return sim.code, sim.name, sim.genericName, sim.quantity,sim.servingSize, count(r) as score order by score desc limit 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar product to Magnum batonnet classic\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {name:\"Batonnet Classic\"})-[r:HAS_ALLERGEN|HAS_GROUP1|HAS_GROUP2|HAS_LABEL*2]-(sim:Product)\n",
    "return sim.code, sim.name, sim.genericName, sim.quantity,sim.servingSize, count(r) as score order by score desc limit 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar product to Magnum batonnet classic that is vegan\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {name:\"Batonnet Classic\"})-[r:HAS_ALLERGEN|HAS_GROUP1|HAS_GROUP2|HAS_LABEL*2]-(sim:Product)-[:HAS_LABEL]->(:Label {name:\"vegan\"})\n",
    "return sim.code, sim.name, sim.genericName, sim.quantity,sim.servingSize, count(r) as Score order by Score desc limit 15\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve this basic product matching?\n",
    "- Extract more descriptive labels\n",
    "    - ingredients, size, weights, nutriscore...\n",
    "    - entity extraction with NLP libraries or LLMs like OpenAI\n",
    "- Use Graph Data Science\n",
    "    - node similarity\n",
    "    - Graph embeddings + KNN\n",
    "- Curate, clean and organize labels\n",
    "    - Taxonomies and ontologies\n",
    "    - Can be done manually (experts) or using automatic procedures (Ontologies, GML node classification or link prediction)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ingredients as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingredients\n",
    "ing_df = df.dropna(subset=['ingredients_text_en'])\n",
    "ing_df.ingredients_text_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_df['ing'] = ing_df['ingredients_text_en'].str.replace(r\"\\(.*\\)\",\"\") # remove what's inside parentheses\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(r\"\\[.*\\]\",\"\")\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\"_\",\"\") # remove \"_\"\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\"  \",\" \")\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\" ,\",\",\").apply(str.lower)\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\".\",\"\")\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\", ,\",\",\")\n",
    "ing_df['ing'] = ing_df['ing'].str.replace(\",,\",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ing_df.ing.str.split(\",\",expand=True).stack().value_counts()).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ingredients as nodes\n",
    "gds.run_cypher(\n",
    "\"\"\"\n",
    "unwind $df as df\n",
    "with df, split(df['ing'],\", \") as ingredients\n",
    "unwind ingredients as ingredient\n",
    "match (p:Product {code: df['code']})\n",
    "merge (i:Ingredient {name:ingredient})\n",
    "merge (p)-[:HAS_INGREDIENT]->(i)\n",
    "\"\"\",\n",
    "params = {'df':ing_df.dropna(subset=['ing']).to_dict(orient='records')}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Find similar products with ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ingredients\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {code:1216486})-[:HAS_INGREDIENT]-(i:Ingredient)-[:HAS_INGREDIENT]-(sim:Product)\n",
    "WITH p, sim, collect(i.name) as ingredients\n",
    "return sim.code, sim.name, sim.genericName, sim.quantity,sim.servingSize, ingredients, size(ingredients) as score order by score desc\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar product to Magnum batonnet classic\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {name:\"Batonnet Classic\"})-[:HAS_INGREDIENT]-(i:Ingredient)-[:HAS_INGREDIENT]-(sim:Product)\n",
    "WITH p, sim, collect(i.name) as ingredients\n",
    "return sim.code, sim.name, sim.genericName, ingredients, size(ingredients) as score order by score desc limit 15\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar product to Magnum batonnet classic using all labels\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (p:Product {name:\"Batonnet Classic\"})-[r:HAS_ALLERGEN|HAS_GROUP1|HAS_GROUP2|HAS_LABEL|HAS_INGREDIENT*2]-(sim:Product)\n",
    "return sim.code, sim.name, sim.genericName, sim.quantity,sim.servingSize, count(r) as Score order by Score desc limit 15\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Product Matching using Similarities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 fastRP + Knn on allergen, category and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we will use compute similarities between Bread product only\n",
    "# create Bread label \n",
    "gds.run_cypher(\"\"\"\n",
    "    match (p:Product)-[:HAS_GROUP1]->(c:Category {name:\"bread\"})\n",
    "    set p:Bread\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, _= gds.graph.project('simcat', \n",
    "    ['Bread','Category','Label','Allergen'],\n",
    "    {'HAS_ALLERGEN':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_CATEGORY':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_GROUP2':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_LABEL':{'orientation':'UNDIRECTED'}\n",
    "     }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to use nodeSimilarity directly. This is an example of results\n",
    "gds.nodeSimilarity.stream(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But fastRP + KNN will be used in the rest of the demo\n",
    "# This is an example of fastRP embeddings\n",
    "gds.fastRP.stream(g,embeddingDimension=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms in Graph Data Science can be chained\n",
    "gds.fastRP.mutate(g,embeddingDimension=128, mutateProperty='fastRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.knn.write(g,nodeLabels=['Bread'], topK=10, nodeProperties=['fastRP'],writeRelationshipType='SIMILAR_TO',writeProperty='score')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMILAR_TO relationships can then be shown in Bloom. Use Louvain in Bloom to display clusters of bread types."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Product reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of query to find similar products from the same brand. \n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (b:Brand)--(b1:Bread)-[r:SIMILAR_TO]->(b2:Bread)--(b)\n",
    "RETURN b1.name, b2.name, b.name, r.score as score order by score desc\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Improve Product classification by learning Taxonomy from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute co-ocurence\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (c:Category)\n",
    "WITH c, count{ (c)<-[:HAS_CATEGORY]-() } as totalCount\n",
    "MATCH (c)<-[:HAS_CATEGORY]-(p)-[:HAS_CATEGORY]->(relatedCategory)\n",
    "WITH c, relatedCategory, toFloat(count(p)) as countp, totalCount\n",
    "CREATE (c)-[:CO_OCCURS {index: countp/ totalCount}]->(relatedCategory)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer same-as relationships \n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (c1)-[co1:CO_OCCURS {index:1}]->(c2),\n",
    "    (c2)-[co2:CO_OCCURS {index:1}]->(c1)\n",
    "WHERE ID(c1) > ID(c2)\n",
    "MERGE (c1)-[:SAME_AS]-(c2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer narrower-than relationships\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (c1)-[:CO_OCCURS {index:1}]->(c2),\n",
    "    (c2)-[co2:CO_OCCURS]->(c1)\n",
    "WHERE co2.index < 1\n",
    "MERGE (c1)-[:NARROWER_THAN]->(c2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce transitive narrower-than relationships\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH (c1)-[:NARROWER_THAN*2..]->(c3),\n",
    "    (c1)-[d:NARROWER_THAN]->(c3)\n",
    "DELETE d\n",
    "\"\"\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis can then be done in Bloom to improve Taxonomy / Categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Improved Product Matching using FastRP + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2, _= gds.graph.project('simall3', \n",
    "    ['Bread','Category','Label','Allergen','Ingredient'],\n",
    "    {'HAS_ALLERGEN':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_CATEGORY':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_GROUP1':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_GROUP2':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_LABEL':{'orientation':'UNDIRECTED'},\n",
    "     'NARROWER_THAN':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_INGREDIENT':{'orientation':'UNDIRECTED'},\n",
    "     'SAME_AS':{'orientation':'UNDIRECTED'}\n",
    "     }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.fastRP.mutate(g2,embeddingDimension=1028, mutateProperty='fastRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.knn.write(g2,nodeLabels=['Bread'], topK=10, nodeProperties=['fastRP'],writeRelationshipType='SIMILAR_TO_ALL',writeProperty='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (p:Product {code:\"5060195901334\"})-[r:SIMILAR_TO_ALL]-(sim)\n",
    "    RETURN p.name, sim.name, r.score as score order by score desc\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Product Matching using free text (product description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using Lucene Full-text search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucene analyzers \n",
    "gds.run_cypher(\"\"\"CALL db.index.fulltext.listAvailableAnalyzers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index on string properties (name, genericName and ingredients as free text)\n",
    "gds.run_cypher(\"\"\"\n",
    "    CREATE FULLTEXT INDEX namesAndIng FOR (n:Product) ON EACH [n.name, n.genericName, n.ingredients]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products can be searched using free text queries\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes(\"namesAndIng\",\"wheat\")\n",
    "    YIELD node, score\n",
    "    RETURN node.name, node.genericName, node.ingredients, score\n",
    "\"\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command does not return any result\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes(\"namesAndIng\",'genericName:bred')\n",
    "    YIELD node, score\n",
    "    RETURN node.name, node.genericName, score\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy search\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes(\"namesAndIng\",'genericName:bred~')\n",
    "    YIELD node, score\n",
    "    RETURN node.name, node.genericName, score\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search and match\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes(\"namesAndIng\",'name:\"chocolate ice cream\"')\n",
    "    YIELD node, score\n",
    "    OPTIONAL MATCH (node)-[:HAS_BRAND]-(b:Brand)\n",
    "    RETURN node.name, node.genericName, node.ingredients, b.name, score\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Using OpenAI text embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part requires:\n",
    "- an OpenAI key\n",
    "- [APOC extended](https://github.com/neo4j-contrib/neo4j-apoc-procedures) version > 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be used only on Bread with genericName size > 20 characters\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Bread) where size(b.genericName) > 20 \n",
    "    set b:Bgname \n",
    "    return count(b)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute OpenAi Embeddings\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Bgname)\n",
    "    WITH b, b.genericName as genName\n",
    "    CALL apoc.ml.openai.embedding([genName],$apiKey) \n",
    "    YIELD embedding\n",
    "    SET b.openAiEmbedding = embedding\n",
    "\"\"\", {'apiKey':openai_api_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI embeddings dimension: 1536\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Bgname) return size(b.openAiEmbedding) limit 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on OpenAIEmbeddings\n",
    "g3,_= gds.graph.project(\"TextEmbed2\", {\"Bgname\": {\"properties\":\"openAiEmbedding\"}},'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.knn.write(g3, topK=10, nodeProperties=['openAiEmbedding'],writeRelationshipType='SIMILAR_OPENAI',writeProperty='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (n:Bgname)-[r:SIMILAR_OPENAI]->(m)\n",
    "    where r.score < 1 AND id(n)>id(m)\n",
    "    return r.score as score, n.genericName, m.genericName\n",
    "    order by score desc limit 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between the different similarity scores\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (n:Bgname)-[r:SIMILAR_OPENAI]->(m)\n",
    "    where r.score < 1 AND id(n)>id(m)\n",
    "    OPTIONAL MATCH (n)-[r2:SIMILAR_TO_ALL]->(m)\n",
    "    return r2.score as nodescore, r.score as score, n.genericName, m.genericName\n",
    "    order by score desc limit 20\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. It is possible to concatenate embeddings for improved similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4, _= gds.graph.project('simall5', \n",
    "    ['Bread','Category','Label','Allergen','Ingredient'],\n",
    "    {'HAS_ALLERGEN':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_CATEGORY':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_GROUP1':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_GROUP2':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_LABEL':{'orientation':'UNDIRECTED'},\n",
    "     'NARROWER_THAN':{'orientation':'UNDIRECTED'},\n",
    "     'HAS_INGREDIENT':{'orientation':'UNDIRECTED'},\n",
    "     'SAME_AS':{'orientation':'UNDIRECTED'}\n",
    "     }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FastRP embeddings\n",
    "gds.fastRP.write(g4,embeddingDimension=1028, writeProperty=\"FastRP_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate fastRP and OpenAI Embeddings\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Bgname)\n",
    "    SET b.totalEmbeddings = b.FastRP_all + b.openAiEmbedding\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding size is now 2564\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH (b:Bgname)\n",
    "    RETURN size(b.totalEmbeddings) limit 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on Concatenated Embeddings\n",
    "g5,_= gds.graph.project(\"AllEmbed2\", {\"Bgname\": {\"properties\":\"totalEmbeddings\"}},'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.knn.write(g5, topK=10, nodeProperties=['totalEmbeddings'],writeRelationshipType='SIMILAR_TOTAL_EMB',writeProperty='score')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results in Bloom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Using OpenAI embeddings for online product matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"bake at home french baguette\"\n",
    "\n",
    "gds.run_cypher(\"\"\"\n",
    "\n",
    "    CALL apoc.ml.openai.embedding([$question],$apiKey) \n",
    "    YIELD embedding\n",
    "    MATCH (b:Bgname)\n",
    "    WITH b, gds.similarity.cosine(embedding, b.openAiEmbedding) AS score\n",
    "    RETURN b.name, score order by score desc\n",
    "\"\"\", {'apiKey':openai_api_key, 'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of OpenAI embedding matching queries can be chained with regular cypher queries\n",
    "question = \"bake at home french baguette\"\n",
    "\n",
    "gds.run_cypher(\"\"\"\n",
    "\n",
    "    CALL apoc.ml.openai.embedding([$question],$apiKey) \n",
    "    YIELD embedding\n",
    "    MATCH (b:Bgname)-[:HAS_LABEL]->(:Label {name:\"vegan\"})\n",
    "    WITH b, gds.similarity.cosine(embedding, b.openAiEmbedding) AS score\n",
    "    RETURN b.name, score order by score desc\n",
    "\"\"\", {'apiKey':openai_api_key, 'question':question})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT \n",
    "- Any embeddings, like images, can be stored on external node (so several images per product is possible)\n",
    "\n",
    "- Customers can be imported as nodes, with (:Customer)-[:PURCHASED]-(:Product) or (:Customer)-[:VIEWED]-(:Product) relationships\n",
    "\n",
    "    - Similar segmentation can be done on Customers (vegan, halal...) to improve customer recommendation\n",
    "\n",
    "    - SIMILAR_TO relationships can be computed on customer to allow hyper personalisation\n",
    "    \n",
    "    - Using apoc.ml.openai.completion, product descriptions can be personalised on the fly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
